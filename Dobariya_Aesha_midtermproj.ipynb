{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95e3df1-99ab-4de7-a41f-351436d594b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "321d741b-072d-483b-85f8-66d17bef6b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 datasets created and saved in the Downloads folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Define the items available in the supermarket\n",
    "items = ['Diapers', 'Detergent', 'Shampoo', 'Toothpaste', 'Cereal', 'Milk', 'Bread', 'Eggs', 'Coffee', 'Soap']\n",
    "\n",
    "# Function to create a dataset of 20 transactions\n",
    "def create_transactions(num_transactions=20, num_items=10):\n",
    "    transactions = []\n",
    "    for _ in range(num_transactions):\n",
    "        # Each transaction contains a random subset of the items, but with some logic to make it non-random\n",
    "        num_items_in_transaction = random.randint(2, 5)  # Each transaction will have between 2 and 5 items\n",
    "        transaction = random.sample(items, num_items_in_transaction)\n",
    "        transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "# Save transactions to CSV file in the 'Downloads' folder\n",
    "def save_to_csv(transactions, filename):\n",
    "    # Path to Downloads folder\n",
    "    downloads_folder = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    \n",
    "    # Ensure the file is saved in the Downloads folder\n",
    "    with open(os.path.join(downloads_folder, filename), mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for transaction in transactions:\n",
    "            writer.writerow(transaction)\n",
    "\n",
    "# Generate and save 5 different datasets, each with 20 transactions\n",
    "for i in range(5):\n",
    "    transactions = create_transactions(num_transactions=20)\n",
    "    save_to_csv(transactions, f'dataset_{i+1}.csv')\n",
    "\n",
    "print(\"5 datasets created and saved in the Downloads folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df869fa7-4a31-4c9e-931e-72857c0b6251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available databases:\n",
      "1. Amazon\n",
      "2. BestBuy\n",
      "3. KMart\n",
      "4. Nike\n",
      "0. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to the database you'd like to choose (or 0 to exit):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 transactions from BestBuy.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter support threshold in % (e.g., 10 for 10%):  30\n",
      "Enter confidence threshold in % (e.g., 20 for 20%):  60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing BestBuy with support 30.0% and confidence 60.0%...\n",
      "\n",
      "Brute Force Frequent Itemsets:\n",
      "{1: {'Cereal': 7, 'Eggs': 8, 'Milk': 11, 'Bread': 7, 'Coffee': 7, 'Detergent': 8, 'Soap': 6, 'Toothpaste': 6}, 2: {('Milk', 'Detergent'): 6}}\n",
      "Brute Force Time: 0.0000s\n",
      "\n",
      "Apriori Frequent Itemsets:\n",
      "   support           itemsets\n",
      "0     0.35            (Bread)\n",
      "1     0.35           (Cereal)\n",
      "2     0.35           (Coffee)\n",
      "3     0.40        (Detergent)\n",
      "4     0.40             (Eggs)\n",
      "5     0.55             (Milk)\n",
      "6     0.30             (Soap)\n",
      "7     0.30       (Toothpaste)\n",
      "8     0.30  (Milk, Detergent)\n",
      "Apriori Rules:\n",
      "   antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0  (Detergent)      (Milk)                 0.4                0.55      0.3   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0        0.75  1.363636      0.08         1.8       0.444444  \n",
      "Apriori Time: 0.0478s\n",
      "\n",
      "FP-Growth Frequent Itemsets:\n",
      "   support           itemsets\n",
      "0     0.40             (Eggs)\n",
      "1     0.35           (Cereal)\n",
      "2     0.55             (Milk)\n",
      "3     0.35           (Coffee)\n",
      "4     0.35            (Bread)\n",
      "5     0.40        (Detergent)\n",
      "6     0.30             (Soap)\n",
      "7     0.30       (Toothpaste)\n",
      "8     0.30  (Milk, Detergent)\n",
      "FP-Growth Rules:\n",
      "   antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0  (Detergent)      (Milk)                 0.4                0.55      0.3   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0        0.75  1.363636      0.08         1.8       0.444444  \n",
      "FP-Growth Time: 0.0000s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "from itertools import combinations\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "file_paths = {\n",
    "    \"Amazon\": r\"C:\\Users\\DELL\\Downloads\\Dobariya_Aesha_midtermproj\\amazon.csv\",\n",
    "    \"BestBuy\": r\"C:\\Users\\DELL\\Downloads\\Dobariya_Aesha_midtermproj\\BestBuy.csv\",\n",
    "    \"KMart\": r\"C:\\Users\\DELL\\Downloads\\Dobariya_Aesha_midtermproj\\Kmart.csv\",\n",
    "    \"Nike\": r\"C:\\Users\\DELL\\Downloads\\Dobariya_Aesha_midtermproj\\Nike.csv\"\n",
    "}\n",
    "\n",
    "# Extract transactions from CSV file\n",
    "def load_transactions(file_path):\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        transactions = [list(filter(None, row)) for row in reader]  # Filter out empty items in rows\n",
    "    return transactions\n",
    "\n",
    "# Applying Brute force method to generate frequent items\n",
    "def generate_frequent_itemsets(transactions, support_threshold):\n",
    "    item_count = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_count[item] = item_count.get(item, 0) + 1\n",
    "\n",
    "    frequent_itemsets = {1: {item: count for item, count in item_count.items() if count / len(transactions) >= support_threshold}}\n",
    "\n",
    "    k = 2\n",
    "    while True:\n",
    "        prev_itemsets = list(frequent_itemsets[k - 1].keys())\n",
    "        new_itemsets = list(combinations(prev_itemsets, k))\n",
    "        item_count = {}\n",
    "        for transaction in transactions:\n",
    "            transaction_set = set(transaction)\n",
    "            for itemset in new_itemsets:\n",
    "                if set(itemset).issubset(transaction_set):\n",
    "                    item_count[itemset] = item_count.get(itemset, 0) + 1\n",
    "\n",
    "        frequent_itemsets[k] = {itemset: count for itemset, count in item_count.items() if count / len(transactions) >= support_threshold}\n",
    "        if not frequent_itemsets[k]:\n",
    "            del frequent_itemsets[k]\n",
    "            break\n",
    "        k += 1\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Applying Apriori Algorithm\n",
    "def apriori_algorithm(transactions, support_threshold, confidence_threshold):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = apriori(df, min_support=support_threshold, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_threshold)\n",
    "\n",
    "    return frequent_itemsets, rules\n",
    "\n",
    "# Applying FP-Growth Algorithm\n",
    "def fpgrowth_algorithm(transactions, support_threshold, confidence_threshold):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = fpgrowth(df, min_support=support_threshold, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_threshold)\n",
    "\n",
    "    return frequent_itemsets, rules\n",
    "\n",
    "# Comparing by timing function\n",
    "def measure_execution_time(algorithm_func, *args):\n",
    "    start_time = time.time()\n",
    "    result = algorithm_func(*args)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "# Source code\n",
    "while True:\n",
    "    # user-defined entry or exit\n",
    "    print(\"\\nAvailable databases:\")\n",
    "    for i, name in enumerate(file_paths.keys(), 1):\n",
    "        print(f\"{i}. {name}\")\n",
    "    print(\"0. Exit\")\n",
    "    \n",
    "    choice = int(input(\"Enter the number corresponding to the database you'd like to choose (or 0 to exit): \"))\n",
    "\n",
    "    # Exit the loop if the user chooses 0\n",
    "    if choice == 0:\n",
    "        print(\"Exiting the program.\")\n",
    "        break\n",
    "\n",
    "    #selected database\n",
    "    db_name = list(file_paths.keys())[choice - 1]\n",
    "\n",
    "    # Load the selected transactions\n",
    "    transactions = load_transactions(file_paths[db_name])\n",
    "    print(f\"Loaded {len(transactions)} transactions from {db_name}.\")\n",
    "\n",
    "    # User-defined for support and confidence thresholds\n",
    "    support_threshold = float(input(\"Enter support threshold in % (e.g., 10 for 10%): \")) / 100\n",
    "    confidence_threshold = float(input(\"Enter confidence threshold in % (e.g., 20 for 20%): \")) / 100\n",
    "\n",
    "    print(f\"\\nProcessing {db_name} with support {support_threshold * 100}% and confidence {confidence_threshold * 100}%...\")\n",
    "\n",
    "    # Brute Force\n",
    "    bf_result, bf_time = measure_execution_time(generate_frequent_itemsets, transactions, support_threshold)\n",
    "    print(f\"\\nBrute Force Frequent Itemsets:\\n{bf_result}\")\n",
    "    print(f\"Brute Force Time: {bf_time:.4f}s\")\n",
    "\n",
    "    # Apriori\n",
    "    apriori_result, apriori_time = measure_execution_time(apriori_algorithm, transactions, support_threshold, confidence_threshold)\n",
    "    print(f\"\\nApriori Frequent Itemsets:\\n{apriori_result[0]}\")\n",
    "    print(f\"Apriori Rules:\\n{apriori_result[1]}\")\n",
    "    print(f\"Apriori Time: {apriori_time:.4f}s\")\n",
    "\n",
    "    # FP-Growth\n",
    "    fp_result, fp_time = measure_execution_time(fpgrowth_algorithm, transactions, support_threshold, confidence_threshold)\n",
    "    print(f\"\\nFP-Growth Frequent Itemsets:\\n{fp_result[0]}\")\n",
    "    print(f\"FP-Growth Rules:\\n{fp_result[1]}\")\n",
    "    print(f\"FP-Growth Time: {fp_time:.4f}s\")\n",
    "\n",
    "    #if user wants to analyze different dataset\n",
    "    continue_choice = input(\"\\nDo you want to analyze another dataset? (yes/no): \").strip().lower()\n",
    "    if continue_choice != 'yes':\n",
    "        print(\"Exiting the program.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1095a0-fd34-4e8a-820f-e160fcdf2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Cereal,Eggs,Bread\n",
      "0                             Detergent,Soap\n",
      "1                       Bread,Cereal,Shampoo\n",
      "2        Eggs,Diapers,Detergent,Milk,Shampoo\n",
      "3                           Cereal,Milk,Eggs\n",
      "4                          Coffee,Toothpaste\n",
      "5       Soap,Bread,Shampoo,Coffee,Toothpaste\n",
      "6                    Bread,Soap,Shampoo,Eggs\n",
      "7                Eggs,Diapers,Detergent,Soap\n",
      "8                       Diapers,Coffee,Bread\n",
      "9                          Toothpaste,Cereal\n",
      "10                         Diapers,Detergent\n",
      "11   Shampoo,Toothpaste,Detergent,Soap,Bread\n",
      "12             Toothpaste,Bread,Soap,Diapers\n",
      "13               Bread,Detergent,Coffee,Soap\n",
      "14  Toothpaste,Shampoo,Detergent,Soap,Coffee\n",
      "15                              Cereal,Bread\n",
      "16                           Shampoo,Diapers\n",
      "17                               Milk,Cereal\n",
      "18                Eggs,Coffee,Cereal,Diapers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cereal,Eggs,Bread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detergent,Soap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread,Cereal,Shampoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eggs,Diapers,Detergent,Milk,Shampoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cereal,Milk,Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coffee,Toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soap,Bread,Shampoo,Coffee,Toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bread,Soap,Shampoo,Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eggs,Diapers,Detergent,Soap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Diapers,Coffee,Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Toothpaste,Cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Diapers,Detergent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shampoo,Toothpaste,Detergent,Soap,Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Toothpaste,Bread,Soap,Diapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bread,Detergent,Coffee,Soap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Toothpaste,Shampoo,Detergent,Soap,Coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cereal,Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shampoo,Diapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Milk,Cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Eggs,Coffee,Cereal,Diapers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Cereal,Eggs,Bread\n",
       "0                             Detergent,Soap\n",
       "1                       Bread,Cereal,Shampoo\n",
       "2        Eggs,Diapers,Detergent,Milk,Shampoo\n",
       "3                           Cereal,Milk,Eggs\n",
       "4                          Coffee,Toothpaste\n",
       "5       Soap,Bread,Shampoo,Coffee,Toothpaste\n",
       "6                    Bread,Soap,Shampoo,Eggs\n",
       "7                Eggs,Diapers,Detergent,Soap\n",
       "8                       Diapers,Coffee,Bread\n",
       "9                          Toothpaste,Cereal\n",
       "10                         Diapers,Detergent\n",
       "11   Shampoo,Toothpaste,Detergent,Soap,Bread\n",
       "12             Toothpaste,Bread,Soap,Diapers\n",
       "13               Bread,Detergent,Coffee,Soap\n",
       "14  Toothpaste,Shampoo,Detergent,Soap,Coffee\n",
       "15                              Cereal,Bread\n",
       "16                           Shampoo,Diapers\n",
       "17                               Milk,Cereal\n",
       "18                Eggs,Coffee,Cereal,Diapers"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\Nike.csv\", delimiter=';')\n",
    "print(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6180e0e-5006-44bb-8cd9-6aa6be072bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
